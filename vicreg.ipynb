{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef97df3-f1a8-4bad-94f7-a41e89efc7ff",
   "metadata": {},
   "source": [
    "Objective of this notebook is to recreate vicreg for pretraining purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4805c3b-b8d3-4745-95ed-b55b6db885ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import logging, os\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score as auprc\n",
    "from sklearn.metrics import roc_auc_score as auc_score\n",
    "import keras\n",
    "\n",
    "#from keras.utils import multi_gpu_model\n",
    "from keras.layers import Input, Dense, GRU, Lambda, Permute, Concatenate\n",
    "from keras.models import Model\n",
    "from interpolation_layer import single_channel_interp, cross_channel_interp\n",
    "from mimic_preprocessing import load_data, trim_los, fix_input_format\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(10)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3540b3cd-fea2-4d1f-bdfd-99c80668b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "if '/home/ugrads/n/nickcheng0921/TAMU-MedResearch/' not in sys.path:\n",
    "    sys.path.append('/home/ugrads/n/nickcheng0921/TAMU-MedResearch/')\n",
    "    \n",
    "from helper import hold_out, mean_imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c6daf1-018c-4f29-b987-53e9276e8ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_num = 1\n",
    "epoch = 3\n",
    "hid = 64 #can be 128-512\n",
    "ref_points = 128\n",
    "hours_look_ahead = 48\n",
    "if gpu_num > 0:\n",
    "    batch = 512*gpu_num\n",
    "else:\n",
    "    batch = 512\n",
    "    \n",
    "#nicks notes args\n",
    "vocabulary = 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab5a116-acfa-4a86-b90d-70ada14cc17e",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "adjust # of patients in mimic_preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f52da8-7117-4b07-923d-e946ba09df11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files ...\n",
      "Loading Done with 5000 patients! Nick\n",
      "4532 4532\n",
      "(4532, 12, 200) 4532\n",
      "X shape: (4532, 48, 200), Y shape: (4532,)\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset - explanation in multivariate notebook\n",
    "vitals, label = load_data(look_ahead_time = hours_look_ahead)\n",
    "vitals, timestamps = trim_los(vitals, hours_look_ahead)\n",
    "x, m, T = fix_input_format(vitals, timestamps)\n",
    "mean_imputation(x, m)\n",
    "x = np.concatenate((x, m, T, hold_out(m)), axis=1)  # input format\n",
    "y = np.array(label)\n",
    "print(f\"X shape: {x.shape}, Y shape: {y.shape}\")\n",
    "timestamp = x.shape[2]\n",
    "num_features = x.shape[1] // 4\n",
    "#     have an array representation.\n",
    "# m : (N, D, tn) where m[i,j,k] = 0 means that x[i,j,k] is not observed.\n",
    "# T : (N, D, tn) represents the actual time stamps of observation;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37766c63-75d8-4862-a78b-9a8619ec126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "patient_notes = pickle.load(open('notes_5000_'+str(hours_look_ahead)+'hrs.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d60fc2-de03-48d0-bab5-bcede2354333",
   "metadata": {},
   "source": [
    "# Unsupervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f38b39a6-d27a-4dca-a15d-88fd72add7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customloss(ytrue, ypred):\n",
    "    \"\"\" Autoencoder loss\n",
    "    \"\"\"\n",
    "    # standard deviation of each feature mentioned in paper for MIMIC_III data\n",
    "    wc = np.array([3.33, 23.27, 5.69, 22.45, 14.75, 2.32,\n",
    "                   3.75, 1.0, 98.1, 23.41, 59.32, 1.41])\n",
    "    wc.shape = (1, num_features)\n",
    "    y = ytrue[:, :num_features, :]\n",
    "    m2 = ytrue[:, 3*num_features:4*num_features, :]\n",
    "    m2 = 1 - m2\n",
    "    m1 = ytrue[:, num_features:2*num_features, :]\n",
    "    m = m1*m2\n",
    "    ypred = ypred[:, :num_features, :]\n",
    "    x = (y - ypred)*(y - ypred)\n",
    "    x = x*m\n",
    "    count = tf.reduce_sum(m, axis=2)\n",
    "    count = tf.where(count > 0, count, tf.ones_like(count))\n",
    "    x = tf.reduce_sum(x, axis=2)/count\n",
    "    x = x/(wc**2)  # dividing by standard deviation\n",
    "    x = tf.reduce_sum(x, axis=1)/num_features\n",
    "    print(\"got loss\", tf.reduce_mean(x))\n",
    "    return tf.reduce_mean(x)\n",
    "\n",
    "seed = 0\n",
    "results = {}\n",
    "results['aux loss'] = []\n",
    "results['vic loss'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327fa1dc-1c58-4a40-8379-1bc44e4c55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model https://github.com/eyalzk/sketch_rnn_keras/blob/002931b9abea957a77382688f37d95afbb2ae6cb/seq2seqVAE.py\n",
    "#https://towardsdatascience.com/advanced-keras-constructing-complex-custom-losses-and-metrics-c07ca130a618\n",
    "class FusionModel(object):\n",
    "    def __init__(self):\n",
    "        if gpu_num > 1:\n",
    "            dev = \"/cpu:0\"\n",
    "        else:\n",
    "            dev = \"/gpu:0\"\n",
    "        with tf.device(dev):\n",
    "            self.main_input = Input(shape=(4*num_features, timestamp), name='input')\n",
    "            self.notes_input = Input(shape=(vocabulary), name='notes_input')\n",
    "            self.notes_output = Dense(hid, activation='sigmoid', name='notes_output')(self.notes_input)\n",
    "            self.sci = single_channel_interp(ref_points, hours_look_ahead)\n",
    "            self.cci = cross_channel_interp()\n",
    "            self.interp = self.cci(self.sci(self.main_input))\n",
    "            self.reconst = self.cci(self.sci(self.main_input, reconstruction=True),\n",
    "                          reconstruction=True)\n",
    "            self.aux_output = Lambda(lambda x: x, name='aux_output')(self.reconst)\n",
    "            self.z = Permute((2, 1))(self.interp)\n",
    "            self.z = GRU(hid, activation='tanh', recurrent_dropout=0.2, dropout=0.2, name='series_output')(self.z)\n",
    "            #print(f\"Z SHAPE {z.shape} NOTES SHAPE {notes_input.shape} MERGED SHAPE {merged_input.shape}\")\n",
    "            self.merged_output = Concatenate(name='merged_output')([self.notes_output, self.z])\n",
    "            self.model = Model([self.main_input, self.notes_input], [self.merged_output, self.aux_output])\n",
    "            print(self.model\n",
    "        \n",
    "    def calculate_mse_loss(self, y_true, y_pred):\n",
    "        \"\"\"calculate mse across notes and series output for VICReg\"\"\"\n",
    "        #return K.mean(K.square(self.notes_output - self.z), axis=-1)\n",
    "        return K.mean(y_pred)\n",
    "    \n",
    "class FusionModel2(object):\n",
    "    def __init__(self):\n",
    "        if gpu_num > 1:\n",
    "            dev = \"/cpu:0\"\n",
    "        else:\n",
    "            dev = \"/gpu:0\"\n",
    "        with tf.device(dev):\n",
    "            self.main_input = Input(shape=(4*num_features, timestamp), name='input')\n",
    "            self.notes_input = Input(shape=(vocabulary), name='notes_input')\n",
    "            self.notes_output = Dense(hid, activation='sigmoid', name='notes_output')(self.notes_input)\n",
    "            self.sci = single_channel_interp(ref_points, hours_look_ahead)\n",
    "            self.cci = cross_channel_interp()\n",
    "            self.interp = self.cci(self.sci(self.main_input))\n",
    "            self.reconst = self.cci(self.sci(self.main_input, reconstruction=True),\n",
    "                          reconstruction=True)\n",
    "            self.aux_output = Lambda(lambda x: x, name='aux_output')(self.reconst)\n",
    "            self.z = Permute((2, 1))(self.interp)\n",
    "            self.z = GRU(hid, activation='tanh', recurrent_dropout=0.2, dropout=0.2, name='series_output')(self.z)\n",
    "            #print(f\"Z SHAPE {z.shape} NOTES SHAPE {notes_input.shape} MERGED SHAPE {merged_input.shape}\")\n",
    "            self.model = Model([self.main_input, self.notes_input], [self.aux_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c30ce1-2573-4f55-912b-d60adc29a3d5",
   "metadata": {},
   "source": [
    "## Notes vectorizer\n",
    "Takes input of size n, and vocab of length l.\n",
    "returns vector of (n, l) where l is vocab embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "680b8772-cd85-4ab6-be38-28d51f501eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold: 1\n",
      "Epoch 1/10\n",
      "8/8 - 7s - loss: 0.1864 - merged_output_loss: 0.1864 - aux_output_loss: 0.0000e+00 - 7s/epoch - 816ms/step\n",
      "Epoch 2/10\n",
      "8/8 - 3s - loss: 0.0924 - merged_output_loss: 0.0924 - aux_output_loss: 0.0000e+00 - 3s/epoch - 403ms/step\n",
      "Epoch 3/10\n",
      "8/8 - 3s - loss: 0.0051 - merged_output_loss: 0.0051 - aux_output_loss: 0.0000e+00 - 3s/epoch - 410ms/step\n",
      "Epoch 4/10\n",
      "8/8 - 3s - loss: -7.3775e-02 - merged_output_loss: -7.3775e-02 - aux_output_loss: 0.0000e+00 - 3s/epoch - 401ms/step\n",
      "Epoch 5/10\n",
      "8/8 - 3s - loss: -1.3551e-01 - merged_output_loss: -1.3551e-01 - aux_output_loss: 0.0000e+00 - 3s/epoch - 415ms/step\n",
      "Epoch 6/10\n",
      "8/8 - 4s - loss: -1.8518e-01 - merged_output_loss: -1.8518e-01 - aux_output_loss: 0.0000e+00 - 4s/epoch - 438ms/step\n",
      "Epoch 7/10\n",
      "8/8 - 4s - loss: -2.2222e-01 - merged_output_loss: -2.2222e-01 - aux_output_loss: 0.0000e+00 - 4s/epoch - 447ms/step\n",
      "Epoch 8/10\n",
      "8/8 - 4s - loss: -2.5543e-01 - merged_output_loss: -2.5543e-01 - aux_output_loss: 0.0000e+00 - 4s/epoch - 444ms/step\n",
      "Epoch 9/10\n",
      "8/8 - 4s - loss: -2.7977e-01 - merged_output_loss: -2.7977e-01 - aux_output_loss: 0.0000e+00 - 4s/epoch - 466ms/step\n",
      "Epoch 10/10\n",
      "8/8 - 4s - loss: -2.9945e-01 - merged_output_loss: -2.9945e-01 - aux_output_loss: 0.0000e+00 - 4s/epoch - 450ms/step\n",
      "['loss', 'merged_output_loss', 'aux_output_loss']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "notes_vectorizer = TfidfVectorizer(max_features=vocabulary)\n",
    "from keras.losses import mse\n",
    "from keras import backend as K\n",
    "x1, play = None, None\n",
    "for train, test in kfold.split(np.zeros(len(y)), y):\n",
    "    print(\"Running Fold:\", i+1)\n",
    "    FM = FusionModel()\n",
    "    model = FM.model  # re-initializing every time\n",
    "    kfold_notes_train = [patient_notes[i] for i in train]\n",
    "    kfold_notes_test = [patient_notes[i] for i in test]\n",
    "    notes_tfidf = notes_vectorizer.fit(kfold_notes_train) #train vocab on train set, then use vectorizer on test set\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'merged_output': FM.calculate_mse_loss, 'aux_output': customloss}) #eager needed to view tensors\n",
    "    model.fit(\n",
    "        {'input': x[train], 'notes_input': notes_vectorizer.transform(kfold_notes_train).todense()}, {'merged_output': [], 'aux_output': x[train]},\n",
    "        batch_size=batch,\n",
    "        epochs=epoch,\n",
    "        verbose=2)\n",
    "    #model.metrics_names gives loss names for evaluate\n",
    "    print(model.metrics_names)\n",
    "\n",
    "    i += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12486dd6-c5fc-43d7-a059-a40cb327b52e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold: 1\n",
      "Epoch 1/10\n",
      "got loss Tensor(\"customloss/Mean:0\", shape=(), dtype=float32)\n",
      "got loss Tensor(\"customloss/Mean:0\", shape=(), dtype=float32)\n",
      "8/8 - 1s - loss: 0.3271 - 1s/epoch - 187ms/step\n",
      "Epoch 2/10\n",
      "8/8 - 1s - loss: 0.3271 - 828ms/epoch - 104ms/step\n",
      "Epoch 3/10\n",
      "8/8 - 1s - loss: 0.3271 - 836ms/epoch - 105ms/step\n",
      "Epoch 4/10\n",
      "8/8 - 1s - loss: 0.3271 - 850ms/epoch - 106ms/step\n",
      "Epoch 5/10\n",
      "8/8 - 1s - loss: 0.3271 - 845ms/epoch - 106ms/step\n",
      "Epoch 6/10\n",
      "8/8 - 1s - loss: 0.3271 - 821ms/epoch - 103ms/step\n",
      "Epoch 7/10\n",
      "8/8 - 1s - loss: 0.3271 - 830ms/epoch - 104ms/step\n",
      "Epoch 8/10\n",
      "8/8 - 1s - loss: 0.3271 - 813ms/epoch - 102ms/step\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ccb632f4ef2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         verbose=2)\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m#model.metrics_names gives loss names for evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/late-fusion/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/late-fusion/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m           \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1403\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/late-fusion/lib/python3.7/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1250\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/late-fusion/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[0;32m~/anaconda3/envs/late-fusion/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/late-fusion/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "notes_vectorizer = TfidfVectorizer(max_features=vocabulary)\n",
    "from keras.losses import mse\n",
    "from keras import backend as K\n",
    "x1, play = None, None\n",
    "for train, test in kfold.split(np.zeros(len(y)), y):\n",
    "    print(\"Running Fold:\", i+1)\n",
    "    FM = FusionModel2()\n",
    "    model = FM.model  # re-initializing every time\n",
    "    kfold_notes_train = [patient_notes[i] for i in train]\n",
    "    kfold_notes_test = [patient_notes[i] for i in test]\n",
    "    notes_tfidf = notes_vectorizer.fit(kfold_notes_train) #train vocab on train set, then use vectorizer on test set\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={'aux_output': customloss},\n",
    "        loss_weights={'aux_output': 1.}) #eager needed to view tensors\n",
    "    model.fit(\n",
    "        {'input': x[train], 'notes_input': notes_vectorizer.transform(kfold_notes_train).todense()}, {'aux_output': x[train]},\n",
    "        batch_size=batch,\n",
    "        epochs=epoch,\n",
    "        verbose=2)\n",
    "    #model.metrics_names gives loss names for evaluate\n",
    "    print(model.metrics_names)\n",
    "\n",
    "    i += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf56b4-3652-4f26-8f57-05b1be24f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default loss must have y_true w/ y_pred\n",
    "#loss cannot natively see output layers\n",
    "#Loss cannot be applied across layers\n",
    "#no batch size in custom loss\n",
    "#cannot look at loss individually, or else we lose batch info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
